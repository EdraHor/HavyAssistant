"""
–°–µ—Ä–≤–∏—Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ —Å Faster-Whisper (GPU)
"""

import logging
import numpy as np
import torch
from faster_whisper import WhisperModel
from utils.config_loader import config
import threading

logger = logging.getLogger(__name__)

class SpeechRecognitionService:
    """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —Å Faster-Whisper"""

    def __init__(self):
        self.model = None
        self.audio_buffer = []
        self.is_recording = False

        self.sample_rate = config.get('audio.sample_rate', 16000)
        self.sensitivity = config.get('speech_recognition.sensitivity', 5)
        self.noise_floor = 0.01
        self.sensitivity_multiplier = 2.0

        self.silent_frames_count = 0
        self.sound_frames_count = 0
        self.calibration_samples = []
        self.is_calibrating = False

        # –ü–æ—Ä–æ–≥–∏
        self.SILENT_FRAMES_TO_STOP = config.get('speech_recognition.silent_frames_to_stop', 15)
        self.MIN_SOUND_FRAMES = config.get('speech_recognition.min_sound_frames', 3)
        self.CALIBRATION_FRAMES = config.get('speech_recognition.calibration_frames', 30)

        # Callbacks
        self.speech_recognized_callback = None
        self.audio_level_callback = None
        self.noise_floor_callback = None

        # –ó–∞—â–∏—Ç–Ω—ã–π —Ç–∞–π–º–µ—Ä
        self.recording_timer = None

    def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Faster-Whisper"""
        # –ï—Å–ª–∏ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ - –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º
        if self.model:
            logger.info("Whisper —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω, –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º")
            self.stop()  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            return

        model_name = config.get('speech_recognition.model_name', 'large-v3')
        device = config.get('speech_recognition.device', 'cuda')
        compute_type = config.get('speech_recognition.compute_type', 'float16')

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU
        if device == 'cuda' and not torch.cuda.is_available():
            logger.warning("CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ CPU")
            device = 'cpu'
            compute_type = 'int8'

        # –†–∞–∑–º–µ—Ä—ã –º–æ–¥–µ–ª–µ–π –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        model_sizes = {
            'tiny': '75MB',
            'base': '145MB',
            'small': '466MB',
            'medium': '1.5GB',
            'large-v3': '3GB',
            'large-v3-turbo': '1.6GB'
        }

        size = model_sizes.get(model_name, '~1GB')
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ Faster-Whisper: {model_name} ({size}) –Ω–∞ {device} ({compute_type})")
        logger.info(f"‚è≥ –ü–µ—Ä–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-10 –º–∏–Ω—É—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–∏...")
        logger.info(f"üí° –ú–æ–¥–µ–ª—å –∫—ç—à–∏—Ä—É–µ—Ç—Å—è, —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫ –±—É–¥–µ—Ç –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–º")

        self.model = WhisperModel(
            model_name,
            device=device,
            compute_type=compute_type,
            download_root="models",
            num_workers=4
        )

        logger.info("‚úÖ Faster-Whisper –≥–æ—Ç–æ–≤!")

        # Warm-up (–ø–µ—Ä–≤—ã–π –ø—É—Å—Ç–æ–π –ø—Ä–æ–≥–æ–Ω –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ CUDA)
        if device == 'cuda':
            logger.info("–ü—Ä–æ–≥—Ä–µ–≤ GPU...")
            dummy_audio = np.zeros(16000, dtype=np.float32)
            list(self.model.transcribe(dummy_audio, language='ru'))
            logger.info("‚úÖ GPU –≥–æ—Ç–æ–≤!")

    def update_sensitivity(self, level: int):
        """
        –û–±–Ω–æ–≤–∏—Ç—å —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (1-10)

        Args:
            level: 1 = –º–µ–Ω–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ, 10 = –±–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ
        """
        self.sensitivity = level
        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º: —á–µ–º –≤—ã—à–µ level, —Ç–µ–º –Ω–∏–∂–µ –º–Ω–æ–∂–∏—Ç–µ–ª—å –ø–æ—Ä–æ–≥–∞
        self.sensitivity_multiplier = max((11 - level) * 0.3, 0.5)
        logger.info(f"–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {level}/10 (–º–Ω–æ–∂–∏—Ç–µ–ª—å {self.sensitivity_multiplier:.1f})")

    def calibrate_noise_floor(self, duration: float = 2.0):
        """
        –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ñ–æ–Ω–æ–≤–æ–≥–æ —à—É–º–∞ (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)

        Args:
            duration: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        import time
        logger.info(f"üîß –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ñ–æ–Ω–∞ ({duration}—Å)...")
        self.is_calibrating = True
        self.calibration_samples.clear()

        time.sleep(duration)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π sleep, –Ω–µ asyncio

        if self.calibration_samples:
            self.noise_floor = np.mean(self.calibration_samples)
            logger.info(f"‚úÖ –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞: —Ñ–æ–Ω={self.noise_floor:.4f}, –ø–æ—Ä–æ–≥={self.get_voice_threshold():.4f}")

            if self.noise_floor_callback:
                self.noise_floor_callback(self.noise_floor)

        self.is_calibrating = False
        self.calibration_samples.clear()

    def get_voice_threshold(self) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –ø–æ—Ä–æ–≥ –≥–æ–ª–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–æ–Ω–∞ –∏ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        return self.noise_floor * self.sensitivity_multiplier

    def start_recording(self):
        """–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –∫–æ–º–∞–Ω–¥—ã"""
        self.is_recording = True
        self.audio_buffer.clear()
        self.silent_frames_count = 0
        self.sound_frames_count = 0

        logger.info(f"üéôÔ∏è –ó–∞–ø–∏—Å—å –∫–æ–º–∞–Ω–¥—ã (–ø–æ—Ä–æ–≥: {self.get_voice_threshold():.4f})")

        # –ó–∞—â–∏—Ç–Ω—ã–π —Ç–∞–π–º–µ—Ä –Ω–∞ 60 —Å–µ–∫—É–Ω–¥
        if self.recording_timer:
            self.recording_timer.cancel()

        self.recording_timer = threading.Timer(60.0, self._timeout_handler)
        self.recording_timer.start()

    def _timeout_handler(self):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–∞–π–º–∞—É—Ç–∞ –∑–∞–ø–∏—Å–∏"""
        if self.is_recording:
            logger.warning("‚è±Ô∏è –¢–∞–π–º–∞—É—Ç –∑–∞–ø–∏—Å–∏ (60—Å)")
            self._recognize_speech()

    def process_audio(self, audio_data: bytes):
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö
        """
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ RMS
        audio_int16 = np.frombuffer(audio_data, dtype=np.int16)
        rms = np.sqrt(np.mean(audio_int16.astype(np.float32) ** 2)) / 32768.0

        # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞
        if self.is_calibrating:
            self.calibration_samples.append(rms)
            if len(self.calibration_samples) <= self.CALIBRATION_FRAMES:
                if self.audio_level_callback:
                    self.audio_level_callback(rms,
                                              f"–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ {len(self.calibration_samples)}/{self.CALIBRATION_FRAMES}")
            return

        if not self.is_recording:
            return

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–∞
        threshold = self.get_voice_threshold()
        is_voice = rms > threshold

        status = "–¢–∏—à–∏–Ω–∞" if rms < self.noise_floor else "–®—É–º" if rms < threshold else "–ì–û–õ–û–°"

        # –û—Ç–ø—Ä–∞–≤–∫–∞ —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞
        if self.audio_level_callback:
            self.audio_level_callback(rms, status)

        logger.debug(
            f"RMS: {rms:.4f} | –ü–æ—Ä–æ–≥: {threshold:.4f} | –§–æ–Ω: {self.noise_floor:.4f} | –°—Ç–∞—Ç—É—Å: {status} | –ì–æ–ª–æ—Å: {is_voice}")

        # –õ–æ–≥–∏–∫–∞ –∑–∞–ø–∏—Å–∏
        if is_voice:
            self.sound_frames_count += 1
            self.silent_frames_count = 0
            self.audio_buffer.extend(audio_int16)

            # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Ç–∞–π–º–µ—Ä–∞ –ø—Ä–∏ –≥–æ–ª–æ—Å–µ
            if self.recording_timer:
                self.recording_timer.cancel()
            self.recording_timer = threading.Timer(60.0, self._timeout_handler)
            self.recording_timer.start()

            logger.debug(f"üìù –ó–∞–ø–∏—Å—ã–≤–∞—é: –±—É—Ñ–µ—Ä {len(self.audio_buffer) // 1000}K —Å—ç–º–ø–ª–æ–≤")
        else:
            if self.sound_frames_count >= self.MIN_SOUND_FRAMES:
                self.silent_frames_count += 1
                self.audio_buffer.extend(audio_int16)

                logger.debug(f"‚è∏Ô∏è –ü–∞—É–∑–∞ ({self.silent_frames_count}/{self.SILENT_FRAMES_TO_STOP})")

                if self.silent_frames_count >= self.SILENT_FRAMES_TO_STOP:
                    logger.debug("‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–∏—à–∏–Ω—ã ‚Üí —Ä–∞—Å–ø–æ–∑–Ω–∞—é")
                    self._recognize_speech()
            else:
                logger.debug(f"‚è≥ –ñ–¥—É –≥–æ–ª–æ—Å... (–∑–≤—É–∫–æ–≤—ã—Ö –∫–∞–¥—Ä–æ–≤: {self.sound_frames_count}/{self.MIN_SOUND_FRAMES})")

    def _recognize_speech(self):
        """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–π —Ä–µ—á–∏"""
        self.is_recording = False

        if self.recording_timer:
            self.recording_timer.cancel()

        if len(self.audio_buffer) < self.sample_rate:  # –ú–µ–Ω—å—à–µ 1 —Å–µ–∫—É–Ω–¥—ã
            logger.warning(f"–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö ({len(self.audio_buffer)} —Å—ç–º–ø–ª–æ–≤)")
            if self.speech_recognized_callback:
                self.speech_recognized_callback("[—Ç–∏—à–∏–Ω–∞]")
            return

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ float32
        audio_float = np.array(self.audio_buffer, dtype=np.float32) / 32768.0
        self.audio_buffer.clear()

        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(audio_float)//1000}K —Å—ç–º–ø–ª–æ–≤...")

        # –ó–∞–ø—É—Å–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        threading.Thread(target=self._transcribe, args=(audio_float,), daemon=True).start()

    def _transcribe(self, audio: np.ndarray):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ"""
        try:
            beam_size = config.get('speech_recognition.beam_size', 1)
            language = config.get('speech_recognition.language', 'ru')
            vad_filter = config.get('speech_recognition.vad_filter', True)

            segments, info = self.model.transcribe(
                audio,
                language=language,
                beam_size=beam_size,
                vad_filter=vad_filter,
                vad_parameters=dict(min_silence_duration_ms=500)
            )

            # –°–±–æ—Ä —Ç–µ–∫—Å—Ç–∞
            text_parts = []
            for segment in segments:
                text_parts.append(segment.text.strip())
                logger.debug(f"–°–µ–≥–º–µ–Ω—Ç: {segment.text.strip()}")

            result_text = " ".join(text_parts).strip()

            if result_text:
                logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: {result_text}")
                if self.speech_recognized_callback:
                    self.speech_recognized_callback(result_text)
            else:
                logger.info("–ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                if self.speech_recognized_callback:
                    self.speech_recognized_callback("[—Ç–∏—à–∏–Ω–∞]")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            if self.speech_recognized_callback:
                self.speech_recognized_callback("[–æ—à–∏–±–∫–∞]")

    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏ –∏ –æ—á–∏—Å—Ç–∫–∞"""
        self.is_recording = False
        self.is_calibrating = False
        self.audio_buffer.clear()
        self.calibration_samples.clear()
        self.silent_frames_count = 0
        self.sound_frames_count = 0

        # –û—Ç–º–µ–Ω–∞ —Ç–∞–π–º–µ—Ä–æ–≤
        if self.recording_timer:
            self.recording_timer.cancel()
            self.recording_timer = None

        logger.info("Speech recognition –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

    def set_speech_recognized_callback(self, callback):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å callback –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–π —Ä–µ—á–∏"""
        self.speech_recognized_callback = callback

    def set_audio_level_callback(self, callback):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å callback –¥–ª—è —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞"""
        self.audio_level_callback = callback

    def set_noise_floor_callback(self, callback):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å callback –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏"""
        self.noise_floor_callback = callback
